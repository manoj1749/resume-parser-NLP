{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b → EducationDegree\n",
      "tech → EducationDegree\n",
      "amrita vishwa vidyapeetham → ORG\n",
      "( 2021 – 2025 → DATE\n",
      "flutter developer intern → Designation\n",
      "nov 2024 → DATE\n",
      "present → DATE\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"manishiitg/resume-ner\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "text = \"\"\"\n",
    "B.Tech in Computer Science at Amrita Vishwa Vidyapeetham (2021 – 2025)\n",
    "Flutter Developer Intern at Go Eleventh Mile from Nov 2024 to Present\n",
    "\"\"\"\n",
    "\n",
    "ner_results = nlp(text)\n",
    "for res in ner_results:\n",
    "    print(f\"{res['word']} → {res['entity_group']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Education:\n",
      "- {'degree': 'Engineering', 'university': 'Sri Chaitanya College Of Education K K R S Go Ham School', 'date': '2021 – Present - 2019 – 2021'}\n",
      "\n",
      "Work Experience:\n",
      "- {'designation': 'Flutter Developer Intern', 'organization': 'Amrita Mind And Brain Center', 'date': 'November 2024 - Present'}\n",
      "- {'designation': 'Hardware Security Researcher', 'organization': 'Redant', 'date': 'July 2023 - October 202'}\n",
      "- {'designation': 'Flutter Developer', 'organization': 'Ostello Ai', 'date': 'June 2023 - September 202'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import docx2txt\n",
    "import fitz  # PyMuPDF\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import torch\n",
    "\n",
    "# ------------ Load Resume NER Model ------------ #\n",
    "model_name = \"manishiitg/resume-ner\"\n",
    "device = 0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\", device=device)\n",
    "\n",
    "# ------------ Text Extraction ------------ #\n",
    "def extract_text(file_path):\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "    if ext == \".pdf\":\n",
    "        doc = fitz.open(file_path)\n",
    "        return \"\\n\".join([page.get_text() for page in doc])\n",
    "    elif ext == \".docx\":\n",
    "        return docx2txt.process(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Please use PDF or DOCX.\")\n",
    "\n",
    "# ------------ Basic Info (Regex) ------------ #\n",
    "def extract_basic_info(text):\n",
    "    name_match = re.search(r'(?i)^([A-Z][a-z]+(?:\\s+[A-Z][a-z]+){1,2})', text)\n",
    "    email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+', text)\n",
    "    phone_match = re.search(r'(\\+?\\d[\\d\\s\\-\\(\\)]{8,})', text)\n",
    "\n",
    "    return {\n",
    "        \"Name\": name_match.group(1).strip() if name_match else None,\n",
    "        \"Email\": email_match.group(0).strip() if email_match else None,\n",
    "        \"Phone Number\": phone_match.group(0).strip() if phone_match else None\n",
    "    }\n",
    "\n",
    "def clean_output(obj):\n",
    "    return {k: v.strip().title() if isinstance(v, str) and v else v for k, v in obj.items()}\n",
    "\n",
    "# ------------ Structured Resume Info ------------ #\n",
    "def extract_resume_info_structured(text):\n",
    "    sentences = re.split(r'(?<=[\\.\\?\\!\\n])\\s+', text)\n",
    "    education = []\n",
    "    experience = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        ents = ner_pipeline(sent)\n",
    "        if not ents:\n",
    "            continue\n",
    "\n",
    "        tags = defaultdict(str)\n",
    "        dates = []\n",
    "\n",
    "        for ent in ents:\n",
    "            word = re.sub(r\"\\s+\", \" \", ent['word'].replace(\"##\", \"\")).strip()\n",
    "            entity_type = ent['entity_group']\n",
    "            tags[entity_type] += word + \" \"\n",
    "            if entity_type == 'DATE':\n",
    "                dates.append(word)\n",
    "\n",
    "        for key in tags:\n",
    "            tags[key] = tags[key].strip()\n",
    "\n",
    "        date = None\n",
    "        if len(dates) >= 2:\n",
    "            date = f\"{dates[0]} - {dates[1]}\"\n",
    "        elif len(dates) == 1:\n",
    "            date = dates[0]\n",
    "\n",
    "        # === Education ===\n",
    "        is_edu = (\n",
    "            'EducationDegree' in tags or\n",
    "            re.search(r'\\b(b\\.?tech|m\\.?tech|bachelor|master|engineering|intermediate|school|college|university)\\b', sent, re.I)\n",
    "        )\n",
    "        if is_edu and ('ORG' in tags or 'INSTITUTE' in tags):\n",
    "            degree = tags.get('EducationDegree')\n",
    "            university = tags.get('ORG') or tags.get('INSTITUTE')\n",
    "\n",
    "            # Fallback\n",
    "            if not degree:\n",
    "                m = re.search(r'(b\\.?tech|m\\.?tech|bachelor|master|engineering)', sent, re.I)\n",
    "                degree = m.group(0) if m else None\n",
    "\n",
    "            if degree and university:\n",
    "                education.append(clean_output({\n",
    "                    \"degree\": degree,\n",
    "                    \"university\": university,\n",
    "                    \"date\": date\n",
    "                }))\n",
    "\n",
    "        # === Work Experience ===\n",
    "        if 'Designation' in tags:\n",
    "            role = tags.get('Designation')\n",
    "            company = tags.get('ORG') or tags.get('COMPANY')\n",
    "\n",
    "            # Fallback for freelance\n",
    "            if not company:\n",
    "                match = re.search(r'at\\s+([A-Z][a-zA-Z]+)', sent)\n",
    "                company = match.group(1) if match else None\n",
    "\n",
    "            if role and company:\n",
    "                experience.append(clean_output({\n",
    "                    \"designation\": role,\n",
    "                    \"organization\": company,\n",
    "                    \"date\": date\n",
    "                }))\n",
    "\n",
    "    return {\n",
    "        \"Education\": education,\n",
    "        \"Work Experience\": experience\n",
    "    }\n",
    "\n",
    "# ------------ Main ------------ #\n",
    "if __name__ == \"__main__\":\n",
    "    resume_path = \"../test-resume/Manoj Resume.pdf\"  # Update path\n",
    "\n",
    "    if not os.path.exists(resume_path):\n",
    "        print(f\"Error: File '{resume_path}' not found.\")\n",
    "    else:\n",
    "        resume_text = extract_text(resume_path)\n",
    "        parsed_info = extract_resume_info_structured(resume_text)\n",
    "\n",
    "        print(\"\\nEducation:\")\n",
    "        for edu in parsed_info[\"Education\"]:\n",
    "            print(\"-\", edu)\n",
    "\n",
    "        print(\"\\nWork Experience:\")\n",
    "        for exp in parsed_info[\"Work Experience\"]:\n",
    "            print(\"-\", exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BASIC INFO:\n",
      "{'Name': 'Manoj Parasuram \\nSadanala', 'Email': 'manojparasuram.sadhanala@gmail.com', 'Phone Number': '9000830070'}\n",
      "\n",
      "Education:\n",
      "- {'degree': None, 'university': 'Sri Chaitanya College Of Education K K R S Go Ham School', 'date': '2021 – Present - 2019 – 2021'}\n",
      "- {'degree': None, 'university': 'Amrita Mind And Brain Center', 'date': 'December 2021 – May 2024'}\n",
      "\n",
      "Work Experience:\n",
      "- {'designation': 'Flutter Developer Intern', 'organization': 'Amrita Mind And Brain Center', 'date': 'November 2024 - Present'}\n",
      "- {'designation': 'Hardware Security Researcher', 'organization': 'Redant', 'date': 'July 2023 - October 202'}\n",
      "- {'designation': 'Flutter Developer', 'organization': 'Ostello Ai', 'date': 'June 2023 - September 202'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import docx2txt\n",
    "import fitz  # PyMuPDF\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "# ------------ Load Resume NER Model ------------ #\n",
    "\n",
    "model_name = \"manishiitg/resume-ner\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# ------------ Text Extraction ------------ #\n",
    "\n",
    "def extract_text(file_path):\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "    if ext == \".pdf\":\n",
    "        doc = fitz.open(file_path)\n",
    "        return \"\\n\".join([page.get_text() for page in doc])\n",
    "    elif ext == \".docx\":\n",
    "        return docx2txt.process(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Please use PDF or DOCX.\")\n",
    "\n",
    "# ------------ Basic Info (Regex) ------------ #\n",
    "\n",
    "def extract_basic_info(text):\n",
    "    name_match = re.search(r'(?i)^([A-Z][a-z]+(?:\\s+[A-Z][a-z]+){1,2})', text)\n",
    "    email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+', text)\n",
    "    phone_match = re.search(r'(\\+?\\d[\\d\\s\\-\\(\\)]{8,})', text)\n",
    "\n",
    "    return {\n",
    "        \"Name\": name_match.group(1).strip() if name_match else None,\n",
    "        \"Email\": email_match.group(0).strip() if email_match else None,\n",
    "        \"Phone Number\": phone_match.group(0).strip() if phone_match else None\n",
    "    }\n",
    "\n",
    "def clean_output(obj):\n",
    "    return {k: v.strip().title() if isinstance(v, str) and v else v for k, v in obj.items()}\n",
    "\n",
    "# ------------ Helper: Fallback Date Extraction ------------ #\n",
    "\n",
    "def extract_dates_from_text(text):\n",
    "    matches = re.findall(r'(?i)(\\b(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)[a-z]*\\.?\\s*\\d{4})', text)\n",
    "    if len(matches) >= 2:\n",
    "        return f\"{matches[0]} - {matches[1]}\"\n",
    "    elif len(matches) == 1:\n",
    "        return matches[0]\n",
    "    return None\n",
    "\n",
    "# ------------ Structured Resume Info ------------ #\n",
    "\n",
    "def extract_resume_info_structured(text):\n",
    "    sentences = re.split(r'(?<=[\\.\\?\\!\\n])\\s+', text)\n",
    "\n",
    "    education = []\n",
    "    experience = []\n",
    "\n",
    "    last_date = None\n",
    "    last_org = None\n",
    "\n",
    "    for sent in sentences:\n",
    "        ents = ner_pipeline(sent)\n",
    "        if not ents:\n",
    "            continue\n",
    "\n",
    "        tags = defaultdict(str)\n",
    "        date_tokens = []\n",
    "\n",
    "        for ent in ents:\n",
    "            clean_word = re.sub(r\"\\s+\", \" \", ent['word'].replace(\"##\", \"\")).strip()\n",
    "            entity_group = ent['entity_group']\n",
    "\n",
    "            if entity_group == 'DATE':\n",
    "                date_tokens.append(clean_word)\n",
    "            else:\n",
    "                tags[entity_group] += clean_word + \" \"\n",
    "\n",
    "        # Clean final tag strings\n",
    "        for key in tags:\n",
    "            tags[key] = tags[key].strip()\n",
    "\n",
    "        # Date handling (NER or regex fallback)\n",
    "        date = None\n",
    "        if len(date_tokens) >= 2:\n",
    "            date = f\"{date_tokens[0]} - {date_tokens[1]}\"\n",
    "        elif len(date_tokens) == 1:\n",
    "            date = date_tokens[0]\n",
    "        else:\n",
    "            date = extract_dates_from_text(sent)\n",
    "\n",
    "        # Update last known values\n",
    "        if date:\n",
    "            last_date = date\n",
    "        if 'ORG' in tags or 'INSTITUTE' in tags or 'COMPANY' in tags:\n",
    "            last_org = tags.get('ORG') or tags.get('INSTITUTE') or tags.get('COMPANY')\n",
    "\n",
    "        # === Education ===\n",
    "        is_edu = (\n",
    "            'EducationDegree' in tags or\n",
    "            re.search(r'\\b(b\\.tech|m\\.tech|bachelor|master|engineering|intermediate|school|college|university)\\b', sent, re.IGNORECASE)\n",
    "        )\n",
    "\n",
    "        if is_edu:\n",
    "            degree = tags.get('EducationDegree')\n",
    "            org = tags.get('ORG') or tags.get('INSTITUTE') or last_org\n",
    "            if degree or org:\n",
    "                education.append(clean_output({\n",
    "                    \"degree\": degree,\n",
    "                    \"university\": org,\n",
    "                    \"date\": date or last_date\n",
    "                }))\n",
    "\n",
    "        # === Work Experience ===\n",
    "        if 'Designation' in tags:\n",
    "            designation = tags['Designation']\n",
    "            company = tags.get('ORG') or tags.get('COMPANY') or last_org\n",
    "            if designation or company:\n",
    "                experience.append(clean_output({\n",
    "                    \"designation\": designation,\n",
    "                    \"organization\": company,\n",
    "                    \"date\": date or last_date\n",
    "                }))\n",
    "\n",
    "    return {\n",
    "        \"Education\": education,\n",
    "        \"Work Experience\": experience\n",
    "    }\n",
    "\n",
    "# ------------ Main ------------ #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resume_path = \"../test-resume/Siddharth_Reddy_Resume.pdf\"  # Update to your path\n",
    "\n",
    "    if not os.path.exists(resume_path):\n",
    "        print(f\"Error: File '{resume_path}' not found.\")\n",
    "    else:\n",
    "        resume_text = extract_text(resume_path)\n",
    "        basic_info = extract_basic_info(resume_text)\n",
    "        parsed = extract_resume_info_structured(resume_text)\n",
    "\n",
    "        print(\"\\nBASIC INFO:\")\n",
    "        print(basic_info)\n",
    "\n",
    "        for section, items in parsed.items():\n",
    "            print(f\"\\n{section}:\")\n",
    "            for item in items:\n",
    "                print(f\"- {item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
