{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Processing: Achyuth_Resume.docx\n",
      "\n",
      "RESULT:\n",
      "{'name': 'Configuration Management Tools', 'email': 'rsda.sada-8@gmail.com', 'phone': '+1 (124)-456-1232', 'education': [], 'work_experience': []}\n",
      "\n",
      "üìÑ Processing: K Nishanth Java.docx\n",
      "\n",
      "RESULT:\n",
      "{'name': 'Java Developer', 'email': 'asdasfadaf@gmail.com', 'phone': '(424) 324-3454', 'education': [], 'work_experience': []}\n",
      "\n",
      "üìÑ Processing: Manoj Resume.pdf\n",
      "\n",
      "RESULT:\n",
      "{'name': 'Manoj Parasuram \\nSadanala', 'email': 'manojparasuram.sadhanala@gmail.com', 'phone': '9000830070', 'education': [{'degree': 'College', 'university': 'amrita vishwa vidyapeetham', 'date': '2021 ‚Äì present ‚Äì 2019 ‚Äì 2021'}, {'degree': 'College', 'university': None, 'date': 'december 2021 ‚Äì may 2024'}], 'work_experience': [{'designation': 'Flutter Developer Intern', 'organization': 'amrita mind and brain center', 'date': 'november 2024 ‚Äì present'}, {'designation': 'Hardware Security Researcher', 'organization': 'redant', 'date': 'july 2023 ‚Äì october 202'}, {'designation': 'Flutter Developer', 'organization': 'ostello ai', 'date': 'june 2023 ‚Äì september 202'}, {'designation': 'Open Source Contributor', 'organization': None, 'date': 'february 2023 ‚Äì june 202'}, {'designation': 'Gayathri R', 'organization': None, 'date': None}, {'designation': 'Prabhu\\nProjects\\nGait Analysis\\nJune', 'organization': None, 'date': 'june 2024 ‚Äì present'}, {'designation': 'Lo', 'organization': None, 'date': 'november 2023 ‚Äì april 2024'}, {'designation': 'Wireless Forensics Framework\\nAugust', 'organization': None, 'date': 'august 2023 ‚Äì february 2024'}, {'designation': 'Hydro', 'organization': None, 'date': 'october 2023 ‚Äì october 202'}, {'designation': 'Alarm', 'organization': None, 'date': 'april 2023 ‚Äì april 202'}, {'designation': 'My Vanam\\nApril', 'organization': None, 'date': 'april 2023 ‚Äì april 202'}]}\n",
      "\n",
      "üìÑ Processing: Resume-Manaya.pdf\n",
      "\n",
      "RESULT:\n",
      "{'name': 'Manaya Kishor Pachpor', 'email': 'pachpor.manaya@gmail.com', 'phone': '+91 9970997099', 'education': [{'degree': 'Institute', 'university': 'srm institute of science and technology', 'date': None}, {'degree': 'Bachelor Of Technology Computer Science', 'university': 'navrachana school sam', 'date': '2022 - 2026'}, {'degree': 'School', 'university': None, 'date': '2015 - 2022'}], 'work_experience': [{'designation': 'Larsen', 'organization': 'larsen & toubro hydrocarbon engineering limited', 'date': None}, {'designation': 'Development Intern', 'organization': None, 'date': None}, {'designation': 'Kzilla', 'organization': None, 'date': 'present'}]}\n",
      "\n",
      "üìÑ Processing: Resume.pdf\n",
      "\n",
      "RESULT:\n",
      "{'name': 'Computer Science Engineering', 'email': 'mathepranav007@gmail.com', 'phone': '+91-7032775677', 'education': [{'degree': 'Institute', 'university': 'indian institute of information technology', 'date': None}], 'work_experience': []}\n",
      "\n",
      "üìÑ Processing: Siddharth_Reddy_Resume.pdf\n",
      "\n",
      "RESULT:\n",
      "{'name': 'Anthireddy Siddharth Reddy', 'email': 'siddharthreddy2812@gmail.com', 'phone': '+916281287188', 'education': [{'degree': 'B Tech', 'university': 'amrita vishwa', 'date': '2021 ‚Äì 2025 ‚Äì 2019 ‚Äì 2021'}], 'work_experience': [{'designation': 'Ai Full Stack Developer', 'organization': 'symbosystems', 'date': 'oct 2024 ‚Äì present'}, {'designation': 'Frontend Developer', 'organization': None, 'date': 'jul 2023 ‚Äì apr 202'}, {'designation': 'Projects\\nMeeting Scheduler Agent\\nOct', 'organization': None, 'date': 'oct 202 ‚Äì nov 202'}, {'designation': 'Cricket Player Performance Analysis', 'organization': None, 'date': 'jun 2024 ‚Äì present'}, {'designation': 'Remote Forest Fire Sensing Using Iot', 'organization': None, 'date': 'may 202'}]}\n",
      "\n",
      "üìÑ Processing: Sri Charan Reddy React_Node.docx\n",
      "\n",
      "RESULT:\n",
      "{'name': 'Sri Charan Reddy Alugubelly', 'email': 'sy04@gmail.com', 'phone': '+1 1234231232', 'education': [], 'work_experience': []}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import docx2txt\n",
    "import fitz  # PyMuPDF\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Optional\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "# Suppress tqdm warning\n",
    "os.environ[\"TQDM_DISABLE\"] = \"1\"\n",
    "\n",
    "# ------------ Load Resume NER Model ------------ #\n",
    "model_name = \"manishiitg/resume-ner\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Use GPU if available\n",
    "device = 0 if os.environ.get(\"CUDA_VISIBLE_DEVICES\", None) else -1\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\", device=device)\n",
    "\n",
    "# ------------ Text Extraction ------------ #\n",
    "def extract_text(file_path: str) -> str:\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "    if ext == \".pdf\":\n",
    "        doc = fitz.open(file_path)\n",
    "        return \"\\n\".join([page.get_text() for page in doc])\n",
    "    elif ext == \".docx\":\n",
    "        return docx2txt.process(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use PDF or DOCX.\")\n",
    "\n",
    "# ------------ Enhanced Basic Info Extraction ------------ #\n",
    "def extract_basic_info(text: str) -> Dict[str, str]:\n",
    "    # Improved name extraction - looks near contact info\n",
    "    email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+', text)\n",
    "    phone_match = re.search(r'(?:\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b', text)\n",
    "    \n",
    "    # Look for name in the lines above email/phone\n",
    "    name = None\n",
    "    if email_match or phone_match:\n",
    "        contact_pos = email_match.start() if email_match else phone_match.start()\n",
    "        preceding_text = text[:contact_pos]\n",
    "        # Look for the most name-like text in the preceding lines\n",
    "        name_candidates = re.findall(r'^(?:[A-Z][a-z]+(?:\\s+[A-Z][a-z]+){1,3})(?=\\s*[\\n\\r])', preceding_text, re.MULTILINE)\n",
    "        if name_candidates:\n",
    "            name = name_candidates[-1]  # Take the last one before contact info\n",
    "\n",
    "    return {\n",
    "        \"name\": name.strip() if name else None,\n",
    "        \"email\": email_match.group(0).strip() if email_match else None,\n",
    "        \"phone\": phone_match.group(0).strip() if phone_match else None\n",
    "    }\n",
    "\n",
    "def clean_output(obj: Dict[str, str]) -> Dict[str, str]:\n",
    "    cleaned = {}\n",
    "    for k, v in obj.items():\n",
    "        if isinstance(v, str):\n",
    "            v = v.strip()\n",
    "            if k == \"date\":\n",
    "                # Clean up date formats\n",
    "                v = re.sub(r'(\\d{4})\\s*‚Äì\\s*(\\d{4})\\s*-\\s*(\\d{4})\\s*‚Äì\\s*(\\d{4})', r'\\1‚Äì\\2', v)\n",
    "                v = re.sub(r'(\\b[A-Za-z]{3}\\b \\d{4})[\\s-]+([A-Za-z]{3}\\b \\d{4})', r'\\1 ‚Äì \\2', v)\n",
    "            elif k in [\"degree\", \"designation\"]:\n",
    "                v = v.title()\n",
    "        cleaned[k] = v if v else None\n",
    "    return cleaned\n",
    "\n",
    "# ------------ Enhanced Structured Resume Info ------------ #\n",
    "def extract_resume_info_structured(text: str) -> Dict[str, List[Dict[str, str]]]:\n",
    "    # First try to identify resume sections\n",
    "    section_pattern = r'(?:^|\\n)\\s*(Education|Work Experience|Experience|Employment|Academic Background)\\s*(?:\\n|$)'\n",
    "    sections = re.split(section_pattern, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    education = []\n",
    "    experience = []\n",
    "    \n",
    "    # Process each section with context\n",
    "    for i in range(1, len(sections), 2):\n",
    "        section_title = sections[i].lower()\n",
    "        section_content = sections[i+1]\n",
    "        \n",
    "        sentences = re.split(r'(?<=[\\.\\?\\!\\n])\\s+', section_content)\n",
    "        \n",
    "        for sent in sentences:\n",
    "            if not sent.strip():\n",
    "                continue\n",
    "                \n",
    "            ents = ner_pipeline(sent)\n",
    "            if not ents:\n",
    "                continue\n",
    "\n",
    "            tags = defaultdict(str)\n",
    "            date_tokens = []\n",
    "            org_tokens = []\n",
    "            degree_tokens = []\n",
    "\n",
    "            for ent in ents:\n",
    "                clean_word = re.sub(r\"\\s+\", \" \", ent['word'].replace(\"##\", \"\")).strip()\n",
    "                entity_type = ent['entity_group']\n",
    "                \n",
    "                if entity_type == 'DATE':\n",
    "                    if re.match(r'^(?:19|20)\\d{2}|[A-Za-z]{3}', clean_word):  # Basic date validation\n",
    "                        date_tokens.append(clean_word)\n",
    "                elif entity_type in ['ORG', 'INSTITUTE', 'COMPANY']:\n",
    "                    org_tokens.append(clean_word)\n",
    "                elif entity_type == 'EducationDegree':\n",
    "                    degree_tokens.append(clean_word)\n",
    "                \n",
    "                tags[entity_type] += clean_word + \" \"\n",
    "\n",
    "            for key in tags:\n",
    "                tags[key] = tags[key].strip()\n",
    "\n",
    "            # Improved date parsing\n",
    "            date = None\n",
    "            if len(date_tokens) >= 2:\n",
    "                date = f\"{date_tokens[0]} ‚Äì {date_tokens[1]}\"\n",
    "            elif len(date_tokens) == 1:\n",
    "                date = date_tokens[0]\n",
    "\n",
    "            # === Enhanced Education Detection ===\n",
    "            degree_keywords = r'\\b(b\\.?\\s*tech|m\\.?\\s*tech|bachelor|master|b\\.?\\s*[es]|m\\.?\\s*[es]|ph\\.?\\s*d|diploma|school|college|university|institute)\\b'\n",
    "            is_edu_sentence = (\n",
    "                'EducationDegree' in tags or\n",
    "                re.search(degree_keywords, sent, re.IGNORECASE) or\n",
    "                any(t in section_title for t in ['education', 'academic'])\n",
    "            )\n",
    "            \n",
    "            if is_edu_sentence:\n",
    "                # Get the most specific degree first\n",
    "                degree = \" \".join(degree_tokens) if degree_tokens else None\n",
    "                if not degree:\n",
    "                    degree_match = re.search(degree_keywords, sent, re.IGNORECASE)\n",
    "                    degree = degree_match.group(0).strip() if degree_match else None\n",
    "                \n",
    "                # Use the first org token if available\n",
    "                university = org_tokens[0] if org_tokens else None\n",
    "                \n",
    "                if degree or university:  # Only add if we have meaningful data\n",
    "                    education.append(clean_output({\n",
    "                        \"degree\": degree,\n",
    "                        \"university\": university,\n",
    "                        \"date\": date\n",
    "                    }))\n",
    "                    continue  # Skip work exp detection for education sentences\n",
    "\n",
    "            # === Enhanced Work Experience Detection ===\n",
    "            if 'Designation' in tags or any(t in section_title for t in ['experience', 'employment']):\n",
    "                role = tags.get('Designation')\n",
    "                if not role:\n",
    "                    # Try to extract role from sentence start\n",
    "                    role_match = re.match(r'^([A-Z][a-z]+(?:\\s+[A-Za-z]+)*)', sent)\n",
    "                    role = role_match.group(1) if role_match else None\n",
    "                \n",
    "                # Use the first org token if available\n",
    "                company = org_tokens[0] if org_tokens else None\n",
    "                \n",
    "                # Skip if it's clearly not a work experience (e.g., education org)\n",
    "                if company and any(edu.get('university') == company for edu in education):\n",
    "                    continue\n",
    "                    \n",
    "                if role:  # Only add if we have at least a role\n",
    "                    experience.append(clean_output({\n",
    "                        \"designation\": role,\n",
    "                        \"organization\": company,\n",
    "                        \"date\": date\n",
    "                    }))\n",
    "\n",
    "    return {\n",
    "        \"education\": education,\n",
    "        \"work_experience\": experience\n",
    "    }\n",
    "\n",
    "# ------------ Batch Folder Parser ------------ #\n",
    "def process_resumes_in_folder(folder_path: str):\n",
    "    for file_name in sorted(os.listdir(folder_path)):\n",
    "        if not file_name.lower().endswith(('.pdf', '.docx')):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f\"\\nüìÑ Processing: {file_name}\")\n",
    "\n",
    "        try:\n",
    "            text = extract_text(file_path)\n",
    "            basic_info = extract_basic_info(text)\n",
    "            structured = extract_resume_info_structured(text)\n",
    "\n",
    "            result = {\n",
    "                \"name\": basic_info[\"name\"],\n",
    "                \"email\": basic_info[\"email\"],\n",
    "                \"phone\": basic_info[\"phone\"],\n",
    "                \"education\": structured[\"education\"],\n",
    "                \"work_experience\": structured[\"work_experience\"]\n",
    "            }\n",
    "            \n",
    "            # Post-processing to clean up results\n",
    "            if not result[\"name\"]:\n",
    "                # Fallback to look for name at document start\n",
    "                name_match = re.search(r'^([A-Z][a-z]+(?:\\s+[A-Z][a-z]+){1,3})(?=\\s*[\\n\\r])', text, re.MULTILINE)\n",
    "                if name_match:\n",
    "                    result[\"name\"] = name_match.group(1).strip()\n",
    "            \n",
    "            print(\"\\nRESULT:\")\n",
    "            print(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error processing {file_name}: {e}\")\n",
    "\n",
    "# ------------ Run Parser ------------ #\n",
    "process_resumes_in_folder(\"../test-resume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
